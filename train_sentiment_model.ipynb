{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGvU2kQO5RUB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers datasets peft accelerate evaluate scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNgqYjWk5LqK"
      },
      "outputs": [],
      "source": [
        "#Install and use wandb for performing a Hyper-parameter sweep\n",
        "!pip install -U wandb --quiet          # if not already installed\n",
        "import wandb\n",
        "wandb.login()                          # paste the API key when asked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Zd43Jg5Uhm"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6Ga0seTFMAX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "df = pd.read_json(\"hr_sentiment_starter.jsonl\", lines=True)\n",
        "dataset = Dataset.from_pandas(df)\n",
        "label_map = {\n",
        "    \"highly engaged\": 0,\n",
        "    \"content\": 1,\n",
        "    \"disengaged\": 2,\n",
        "    \"at risk of leaving\": 3\n",
        "}\n",
        "\n",
        "dataset = dataset.map(lambda x: {\"label\": label_map[x[\"label\"]]})\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "dataset['validation'] = dataset.pop('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXDFZ-IPGBXz"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "model_name=\"j-hartmann/emotion-english-distilroberta-base\"\n",
        "\n",
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=4,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoTkS3-855lX"
      },
      "outputs": [],
      "source": [
        "# Tokenize dataset\n",
        "def tokenize(example):\n",
        "    return tokenizer(example['pros_cons'], padding='max_length', truncation=True)\n",
        "\n",
        "tokenized = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmLG2dIC57qa"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"grid\",          # or \"random\", \"bayes\"\n",
        "    \"metric\": {\n",
        "        \"name\": \"eval_f1\",\n",
        "        \"goal\": \"maximize\"\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\":  {\"values\": [2e-5, 5e-5]},\n",
        "        \"per_device_train_batch_size\": {\"values\": [8,16]},\n",
        "        \"num_train_epochs\": {\"values\": [3,4,5]}\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"hr-sentiment-sweep-v2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsIFQHQw6FOU"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
        "    }\n",
        "\n",
        "def sweep_train():\n",
        "    # Fetch current sweep hyper-params from wandb.config\n",
        "    run   = wandb.init()            # project/name is inherited from the sweep\n",
        "    config = run.config\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=\"./results/sentiment-model\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_f1\",\n",
        "        greater_is_better=True,\n",
        "        learning_rate=config.learning_rate,\n",
        "        per_device_train_batch_size=config.per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=config.per_device_train_batch_size,\n",
        "        num_train_epochs=config.num_train_epochs,\n",
        "        report_to=\"wandb\",\n",
        "        run_name=run.name\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model_init=model_init,\n",
        "        args=args,\n",
        "        train_dataset=tokenized[\"train\"],\n",
        "        eval_dataset=tokenized[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    # Save model after training\n",
        "    model_dir = f\"./results/model-{run.id}\"\n",
        "    trainer.save_model(model_dir)\n",
        "\n",
        "    # At the end, log classification report on validation set\n",
        "    preds_output = trainer.predict(tokenized[\"validation\"])\n",
        "    preds  = preds_output.predictions.argmax(-1)\n",
        "    labels = preds_output.label_ids\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    report = classification_report(\n",
        "        labels, preds,\n",
        "        target_names=list(label_map.values()),\n",
        "        output_dict=True\n",
        "    )\n",
        "    wandb.log({\"classification_report\": report})\n",
        "    # Log the artifact\n",
        "    artifact = wandb.Artifact(f\"model-{wandb.run.name}\", type=\"model\")\n",
        "    artifact.add_dir(\"./results/sentiment-model\")  # This is where Trainer saved the model\n",
        "    wandb.log_artifact(artifact)\n",
        "    run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMY-ch4eGvJC",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, function=sweep_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this if you want to load the model from artifact\n",
        "import wandb\n",
        "\n",
        "# Log in first\n",
        "wandb.login()\n",
        "\n",
        "# Restore the best model from W&B\n",
        "run = wandb.init(project=\"hr-sentiment-sweep-v2\", id=\"q8smpdk6\", resume=\"allow\")\n",
        "\n",
        "artifact = run.use_artifact(\"model-worthy-sweep-11:v0\")  # or \"model:v0\" if named that way\n",
        "model_dir = artifact.download()\n"
      ],
      "metadata": {
        "id": "23QcnE53nWet",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this if you want to load the model from local\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_dir = \"./results/model-q8smpdk6\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n"
      ],
      "metadata": {
        "id": "z5vLACEmnmBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "df = pd.read_json(\"employee_reviews_testset_100_each.jsonl\", lines=True)\n",
        "test_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "test_dataset = test_dataset.map(lambda x: {\"label\": label_map[x[\"label\"]]})\n",
        "\n",
        "test_dataset = test_dataset.map(tokenize, batched=True)"
      ],
      "metadata": {
        "id": "LztlWdGqnoPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(model=model, compute_metrics=compute_metrics)\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "0YWK_4HonpoD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}